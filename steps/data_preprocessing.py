import logging
from zenml import step
import pandas as pd
import yaml
import numpy as np
from typing import Tuple
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

logger = logging.getLogger(__name__)

@step
def data_preprocessing(df: pd.DataFrame, max_year:int, config_path: str) -> pd.DataFrame:
    '''
    function to clean and transform raw data. Includes dropping unnecesary data,
    andjusting datatypes, and feature engineering.

    Args:
        df: pd.DataFrame with raw data
        max_year: int, maximum year to consider in the data
        config_path: str to config.yaml file

    Returns:
        pd.DataFrame (cleaned and transformed data)
    '''

    try:
        # notification of step start
        logger.info("Starting data preprocessing...")

        # we consider only previous seasons
        games_df = df[df['season'] <= max_year].copy()

        # season 1999 has no gametime and is really old, so we remove it
        games_df = games_df[games_df['season'] > 1999].reset_index(drop=True)

        # adjust datatype to date
        games_df['gameday'] = pd.to_datetime(games_df['gameday'])

        # set of teams (ideally home and away teams are the same)
        teams_set = set(games_df['home_team']) and set(games_df['away_team'])

        # auxiliar for the concat
        df_list = []

        # create a designed df for each team
        for team in teams_set:
            
            # select games played by the team
            team_df = games_df[(games_df['home_team'] == team)|(games_df['away_team'] == team)].copy().reset_index()

            # add a variable: focus team
            team_df['focus_team'] = team

            # add variable: status
            team_df['focus_team_status'] = np.where(team_df['home_team'] == team,'home','away')

            # add a variable: vs team
            team_df['versus_team'] = np.where(team_df['home_team'] == team, team_df['away_team'], team_df['home_team'])

            # add variables: winner (ties are rare so we consider them as losses)
            team_df['focus_team_score'] = np.where(team_df['focus_team_status'] == 'home', team_df['home_score'], team_df['away_score'])
            team_df['versus_team_score'] = np.where(team_df['focus_team_status'] == 'away', team_df['home_score'], team_df['away_score'])
            team_df['winner'] = np.where(team_df['focus_team_score'] > team_df['versus_team_score'], 1, 0)

            # selection of columns
            team_df = team_df[['game_id', 'focus_team', 'focus_team_status', 'versus_team', 
                            'focus_team_score', 'versus_team_score', 'winner',
                            'season', 'game_type', 'gameday', 'gametime']]
            
            # add columns with info of last ten games
            for i in range(10,len(team_df)):
                team_df.loc[i,'focus_team_ltg_wins'] = sum(team_df.loc[range(i-10,i),'winner'] == 1)
                team_df.loc[i,'focus_team_ltg_score'] = sum(team_df.loc[range(i-10,i),'focus_team_score'])
            
            # append new df in the list
            team_df = df_list.append(team_df)

        # concat all dataframes
        focused_df = pd.concat(df_list, ignore_index=True)

        # get versus team last ten games wins by merging df with itself
        focused_df = pd.merge(
            focused_df,
            focused_df[['game_id','focus_team','focus_team_ltg_wins','focus_team_ltg_score']],
            how = 'left',
            left_on = ['game_id', 'versus_team'],
            right_on = ['game_id','focus_team']
        )

        # drop and rename columns generated by merge
        focused_df = focused_df.drop(columns=['focus_team_y'])
        focused_df = focused_df.rename(columns = {
            'focus_team_x':'focus_team',
            'focus_team_ltg_wins_x':'focus_team_ltg_wins',
            'focus_team_ltg_score_x':'focus_team_ltg_score',
            'focus_team_ltg_wins_y':'versus_team_ltg_wins',
            'focus_team_ltg_score_y':'versus_team_ltg_score'
        })

        # drop games with null values
        focused_df = focused_df.dropna(
            subset=['focus_team_ltg_wins','focus_team_ltg_score','versus_team_ltg_wins','versus_team_ltg_score']
        ).reset_index(drop=True)

        # get config
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        # select section of config
        validation_config = config['data_preprocessing']

        # categorize gametime into day periods
        focused_df['day_period'] = pd.cut(
            focused_df['gametime'].str.slice(0,2).astype(int),
            bins=validation_config['hour_bins'],
            labels=validation_config['hour_labels']
        )

        # sort by date
        focused_df = focused_df.sort_values(by=['gameday','gametime']).reset_index(drop=True)
        
        #notification of step end
        logger.info("Data preprocessing completed.")

        # return the processed dataframe
        return focused_df
    
    except FileNotFoundError as e:
        logger.error(f"❌ Can't find config.yaml file: {e}")
        raise
    except KeyError as e:
        logger.error(f"❌ key missing in config.yaml: {e}")
        raise
    except Exception as e:
        logger.error(f"❌ Unexpected error at preprocessing step: {e}")
        raise

@step
def post_split_preprocessing(X_train: pd.DataFrame, y_train: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    '''
    function to do additional preprocessing after the data split.
    Includes encoding categorical variables.
    Args:
        X_train: pd.DataFrame with training features
        y_train: pd.DataFrame with training target
    Returns:
        Tuple(pd.DataFrame, pd.DataFrame) (processed X_train and y_train)
    '''
    try:
        # notification of step start
        logger.info("Starting post-split data preprocessing...")

        # copy of df to avoid modifying original data
        X_train_proc = X_train.copy()
        y_train_proc = y_train.copy()

        # label encoding for focus team status
        staus_encoder = LabelEncoder()
        X_train_proc['focus_team_status_encoded'] = staus_encoder.fit_transform(X_train_proc['focus_team_status'])
        X_train_proc = X_train_proc.drop(columns=['focus_team_status'])

        # label encoding for game type (we dont use sklearn to start with 1)
        mapping = {'REG':1, 'WC':2, 'DIV':3, 'CON':4, 'SB':5}
        X_train_proc['game_type_encoded'] = X_train_proc['game_type'].map(mapping)
        X_train_proc = X_train_proc.drop(columns=['game_type'])

        # label encoding for day period
        period_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
        filter = X_train_proc[X_train_proc['day_period'] != 'night'][['day_period']]
        period_encoder.fit(filter)
        day_period_encoded = period_encoder.transform(X_train_proc[['day_period']])
        day_period_df = pd.DataFrame(
            day_period_encoded,
            columns = period_encoder.get_feature_names_out(['day_period']),
            index = X_train_proc.index
        )
        X_train_proc = X_train_proc.join(day_period_df)
        X_train_proc = X_train_proc.drop(columns=['day_period'])
        
        # return the processed dataframes
        return X_train_proc, y_train_proc

    except Exception as e:
        logger.error(f"❌ Unexpected error at post-split preprocessing step: {e}")
        raise